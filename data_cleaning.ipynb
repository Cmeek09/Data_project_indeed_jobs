{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and future work\n",
    "\n",
    "The APIs in total got about 500 jobs and the web scraping with selenium yeilded about 1300, so that isn't the most amount of dta but its enough to get some general mertrics and insights, plus the amount of work to unify this will be pretty substancial as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the job descriptions more generalized to get a better feel for the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_job_title(title):\n",
    "    title = str(title).lower()\n",
    "    \n",
    "    if 'hadoop' in title or 'data' in title or 'database' in title or 'spark' in title:\n",
    "        return 'data engineer'\n",
    "    elif 'azure' in title or 'aws' in title or 'cloud' in title:\n",
    "        return 'cloud enginner'\n",
    "    if 'full' in title or 'stack' in title or 'frontend' in title or 'backend' in title or 'front' in title or 'end' in title or 'react' in title or 'angular' in title or '.net' in title or 'node' in title or 'nodejs' in title:\n",
    "        return 'web developer'\n",
    "    elif 'machine learning' in title or 'ai' in title or 'ml' in title or 'quantitative' in title:\n",
    "        return 'data science'\n",
    "    elif 'network' in title or 'security' in title or 'cyber' in title or 'Cyber' in title or 'Cybersecurity' in title:\n",
    "        return 'network engineer'\n",
    "    elif 'andriod' in title or 'ios' in title:\n",
    "        return 'mobile developer'\n",
    "    elif 'nan' in title or 'null' in title:\n",
    "        return 'no title given'\n",
    "    elif 'c++' in title or 'C++' in title or 'java' in title or 'Java' or 'golang' in title or 'python' in title:\n",
    "        return 'software engineer'\n",
    "    else:\n",
    "        return 'software egnineer'\n",
    "\n",
    "# Read the Excel files\n",
    "df1 = pd.read_excel('combined_indeed_jobs.xlsx')\n",
    "df2 = pd.read_excel('indeed_jobs_250.xlsx',sheet_name='cleaned_data')\n",
    "df3 = pd.read_excel('job_data_updated.xlsx')\n",
    "\n",
    "# Apply the job category mapping to each DataFrame\n",
    "df1['Category'] = df1['job_title_lower'].apply(group_job_title)\n",
    "df2['Category'] = df2['job_title_lower'].apply(group_job_title)\n",
    "df3['Category'] = df3['title_lower'].apply(group_job_title)\n",
    "\n",
    "# # Print the updated DataFrames\n",
    "# print(df1.head())\n",
    "# print(df2.head())\n",
    "# print(df3.head())\n",
    "\n",
    "# Save the DataFrames with the new column back to Excel\n",
    "df1.to_excel('combined_indeed_jobs_updated.xlsx', index=False)\n",
    "df2.to_excel('indeed_jobs_250_updated.xlsx', index=False)\n",
    "df3.to_excel('job_data_updated_new.xlsx', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second thing I wanted to find was averaging the salary range out.  Since some data is missing for salaries, if I generalize the categories, I can take the average of those same categories for the position.  This might later turn into getting the numbers based on geo-location, but one step at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Define the salary extraction function\n",
    "def extract_average_salary(salary):\n",
    "    if pd.isna(salary):\n",
    "        return None\n",
    "    else:\n",
    "        cleaned_salary = re.sub(r'[^\\d.,-]', '', salary)\n",
    "        numbers = re.findall(r'\\d+(?:,\\d+)?(?:\\.\\d+)?', cleaned_salary)\n",
    "        \n",
    "        if numbers:\n",
    "            if len(numbers) == 2:\n",
    "                # Extract the two numbers, remove commas, and calculate the average\n",
    "                num1 = numbers[0].replace(',', '')\n",
    "                num2 = numbers[1].replace(',', '')\n",
    "                average = (float(num1) + float(num2)) / 2\n",
    "                return average\n",
    "            elif len(numbers) == 1:\n",
    "                # Return the single given number\n",
    "                return float(numbers[0].replace(',', ''))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Read the Excel file\n",
    "df1 = pd.read_excel('job_data_updated_new.xlsx')\n",
    "\n",
    "# Apply the salary extraction function to the 'salary' column\n",
    "df1['average_salary'] = df1['salary'].apply(extract_average_salary)\n",
    "\n",
    "# Print the 'average_salary' column\n",
    "df1.to_excel('job_data_updated_new.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       102,950.00\n",
      "1       102,050.00\n",
      "2        68,900.00\n",
      "3             None\n",
      "4             None\n",
      "           ...    \n",
      "1558          None\n",
      "1559          None\n",
      "1560    122,500.00\n",
      "1561    127,000.00\n",
      "1562    133,500.00\n",
      "Name: average_salary_fixed, Length: 1563, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import locale\n",
    "\n",
    "# Set the locale for formatting\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('job_data_updated_new.xlsx')\n",
    "\n",
    "# Apply the formatting to the 'average_salary' column\n",
    "df['average_salary_fixed'] = df['average_salary'].apply(lambda x: None if pd.isna(x) else locale.format_string(\"%.2f\", float(x) * 1000, grouping=True))\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df['average_salary_fixed'])\n",
    "\n",
    "# Save the DataFrame with the new column back to Excel\n",
    "df.to_excel('job_data_updated_new.xlsx', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Power BI\n",
    "\n",
    "Power BI offers great functionality like power query and transforming the data to get this into one big dataset without compromising the data, and keeping things easy\n",
    "\n",
    "I was also trying to work to getting the location data standardized becauase aggregating would be difficult if there wasn't any way to have things flushed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "data = pd.read_excel('combined_all_jobs.xlsx')\n",
    "state_ref = pd.read_excel('state_ref_table.xlsx')\n",
    "\n",
    "# Function to find the state from location_clean column\n",
    "def find_state(location):\n",
    "    for index, row in state_ref.iterrows():\n",
    "        if row['State Code'] in location or row['State'] in location:\n",
    "            return row['State']\n",
    "    return None\n",
    "\n",
    "# Apply the function to create the 'State' column\n",
    "data['State'] = data['location_clean'].apply(find_state)\n",
    "\n",
    "# Save the result with the added 'State' column\n",
    "data.to_excel('combined_all_jobs.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
